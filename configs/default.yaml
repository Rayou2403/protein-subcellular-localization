# Experiment configuration
experiment_name: "dual_embedding_fusion"
seed: 42

# Data paths
data:
  metadata_path: "data/processed/splits.csv"
  esmc_h5_path: "data/processed/embeddings/esmc.h5"
  prostt5_h5_path: "data/processed/embeddings/prostt5.h5"
  fasta_path: "data/raw/graphpart_set.fasta"  # For embedding extraction
  num_workers: 4

# Model architecture
model:
  type: "transformer_mlp"  # Options: transformer_mlp, gated_mlp
  esmc_dim: 960  # ESM-C 300M embedding dimension
  prostt5_dim: 1024  # ProtBert/ProstT5 embedding dimension
  hidden_dim: 512
  num_attention_heads: 4
  num_transformer_layers: 2
  num_fusion_layers: 2  # Used only for gated_mlp
  dropout: 0.3
  num_classes: 6
  pooling_type: "attention"  # Options: attention, mean_max
  use_gated_fusion: true

# Training hyperparameters
training:
  batch_size: 32
  learning_rate: 0.0001
  weight_decay: 0.01
  num_epochs: 100
  gradient_clip_norm: 1.0
  early_stopping_patience: 15
  use_amp: false  # Automatic Mixed Precision

  # Loss function
  loss_type: "focal"  # Options: weighted_ce, focal
  focal_gamma: 2.0
  focal_alpha: null  # null means use class weights

  # Sampling strategy
  use_balanced_sampler: true

# Optimizer and scheduler
optimizer:
  type: "adamw"
  betas: [0.9, 0.999]
  eps: 1.0e-8

scheduler:
  type: "cosine"  # Options: cosine, step, plateau
  warmup_epochs: 5
  min_lr: 1.0e-6

# Evaluation
evaluation:
  metrics: ["accuracy", "macro_f1", "mcc", "per_class"]
  save_predictions: true
  save_confusion_matrix: true

# Paths
paths:
  checkpoint_dir: "results/checkpoints"
  log_dir: "results/logs"
  output_dir: "results/evaluation"

# Class names (for visualization)
class_names:
  - "Cytoplasmic"
  - "Cytoplasmic Membrane"
  - "Periplasmic"
  - "Outer Membrane"
  - "Extracellular"
  - "Cell Wall"
